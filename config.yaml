collectors:
  arxiv:
    rate_limit: 1.0
    max_results: 50
    sort_by: submittedDate
    sort_order: descending

storage:
  type: postgresql
  connection_string: "postgresql://stoma:stoma123@localhost:5432/stoma"

analysis:
  enable_nlp: false
  model_name: "en_core_web_sm"
  
  # LLM Analysis Configuration
  enable_llm: true
  llm:
    # Lightweight model configuration for memory efficiency
    provider: "ollama"  # ollama, openai, anthropic
    model: "phi3.5"     # Recommended: phi3.5, qwen2.5:3b, gemma2:2b
    max_tokens: 800     # Reduced for faster responses
    temperature: 0.1    # Low for consistent analysis
    
    # Fallback configuration
    fallback_to_cloud: true
    fallback_provider: "openai"
    fallback_model: "gpt-3.5-turbo"
    
    # Performance settings
    memory_limit_gb: 4.0
    analysis_mode: "balanced"  # fast, balanced, quality

api:
  host: "0.0.0.0"
  port: 8000
  debug: true

logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"